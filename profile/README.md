![logo_with_text](https://github.com/geniusrise/.github/assets/144122/2f8e51ee-0fcd-4f74-90fd-97301ef7943d)

### AI Microservices Ecosystem

<br/>

<h3 align="center">
  <a style="color:#f34960" href="https://docs.geniusrise.ai">Docs</a>
  ||
  <a style="color:#f34960" href="https://github.com/geniusrise/examples">Examples</a>
  ||
  <a style="color:#f34960" href="https://www.youtube.com/@geniusrise">Youtube</a>
  ||
  <a style="color:#f34960" href="https://hub.docker.com/u/geniusrise">Docker</a>
</h3>

<br/>

### Run open source models on different inference engines with YAML configs on local or cloud.

<br/>

# Capabilities

We support hosting models in two ways:
1. APIs
2. Bulk jobs

on the following systems:

1. Kubernetes
2. Openstack

Current direction of the project is to be the open source alternative to [NVIDIA NIM](https://nvidianews.nvidia.com/news/generative-ai-microservices-for-developers) and have support for multiple architectures and inference engines.

# Usage

Read the [TLDR](https://docs.geniusrise.ai/guides/usage/) usage guide.

# Explore

There are [blog articles](https://docs.geniusrise.ai) for each category of task accompanied with [youtube videos](https://www.youtube.com/@geniusrise) and over 300 examples for [text](https://github.com/geniusrise/examples/tree/master/cli/api/text), [vision](https://github.com/geniusrise/examples/tree/master/cli/api/vision) and [audio](https://github.com/geniusrise/examples/tree/master/cli/api/audio) models.

### <span style="color:#e667aa">Links</span>

- **Website**: [geniusrise.ai](https://geniusrise.ai)
- **Docs**: [docs.geniusrise.ai](https://docs.geniusrise.ai)
- **Examples**: [geniusrise/examples](https://github.com/geniusrise/examples)
- **Cloud**: [geniusrise.com](https://geniusrise.com)

# Supports

- [pytorch](https://github.com/pytorch/pytorch)
- [transformers](https://github.com/huggingface/transformers)
- [peft](https://github.com/huggingface/peft)
- [accelerate](https://github.com/huggingface/accelerate)
- [DeepSpeed](https://github.com/microsoft/DeepSpeed)
- [bitsandbytes](https://github.com/TimDettmers/bitsandbytes)
- [AutoAWQ](https://github.com/casper-hansen/AutoAWQ)
- [AutoGPTQ](https://github.com/AutoGPTQ/AutoGPTQ)
- [flash-attention](https://github.com/Dao-AILab/flash-attention)
- [vllm](https://github.com/vllm-project/vllm)
- [llama-cpp-python](https://github.com/abetlen/llama-cpp-python)
- [llama.cpp](https://github.com/ggerganov/llama.cpp)
- [whispercpp](https://github.com/aarnphm/whispercpp)
- [whisper.cpp](https://github.com/ggerganov/whisper.cpp)
- [faster-whisper](https://github.com/SYSTRAN/faster-whisper)

# License

The entire project is Apache 2.0 licensed.

# Contribute

Take a look at [good first issues](https://github.com/orgs/geniusrise/projects/3/views/2?visibleFields=%5B%22Title%22%2C%22Assignees%22%2C%22Status%22%2C%22Labels%22%5D&filterQuery=label%3A%22good+first+issue%22) or [help wanted](https://github.com/orgs/geniusrise/projects/3/views/2?visibleFields=%5B%22Title%22%2C%22Assignees%22%2C%22Status%22%2C%22Labels%22%5D&filterQuery=label%3A%22help+wanted%22) on the [board](https://github.com/orgs/geniusrise/projects/3/views/1).

Or feel free to contact at ixaxaar@geniusrise.ai for more.
